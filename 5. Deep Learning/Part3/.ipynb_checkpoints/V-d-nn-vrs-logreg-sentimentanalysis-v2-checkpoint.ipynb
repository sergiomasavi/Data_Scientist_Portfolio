{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Tarjeta.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Analisis-de-sentimiento-en-opiniones-de-IMDB---LogRes-versus-NN\" data-toc-modified-id=\"Analisis-de-sentimiento-en-opiniones-de-IMDB---LogRes-versus-NN-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Analisis de sentimiento en opiniones de IMDB - LogRes versus NN</a></span></li><li><span><a href=\"#1.-Primer-bloque---Carguemos-las-opiniones-para-aplicar-Bag-of-Words\" data-toc-modified-id=\"1.-Primer-bloque---Carguemos-las-opiniones-para-aplicar-Bag-of-Words-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>1. Primer bloque - Carguemos las opiniones para aplicar Bag of Words</a></span></li><li><span><a href=\"#2.-Primer-bloque---Regresión-Logistica-con-Bag-Of-Words\" data-toc-modified-id=\"2.-Primer-bloque---Regresión-Logistica-con-Bag-Of-Words-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>2. Primer bloque - Regresión Logistica con Bag Of Words</a></span><ul class=\"toc-item\"><li><span><a href=\"#2.1-Cargamos-las-librerias-para-la-Regresión-Logística-y-la-entrenamos-con-cross-validation-buscando-el-mejor-parámetro-C-de-la-regresion-logística\" data-toc-modified-id=\"2.1-Cargamos-las-librerias-para-la-Regresión-Logística-y-la-entrenamos-con-cross-validation-buscando-el-mejor-parámetro-C-de-la-regresion-logística-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>2.1 Cargamos las librerias para la Regresión Logística y la entrenamos con cross validation buscando el mejor parámetro C de la regresion logística</a></span></li></ul></li><li><span><a href=\"#3.Segundo-bloque---Vayamos-a-por-una-red-neuronal\" data-toc-modified-id=\"3.Segundo-bloque---Vayamos-a-por-una-red-neuronal-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>3.Segundo bloque - Vayamos a por una red neuronal</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wmjb9FYgCtGr"
   },
   "source": [
    "## Analisis de sentimiento en opiniones de IMDB - LogRes versus NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4UjqbX3ACtGs"
   },
   "source": [
    "## 1. Primer bloque - Carguemos las opiniones para aplicar Bag of Words\n",
    "\n",
    "Necesitaremos pandas y el CountVectorizer de sklearn para aplicar bag of words sobre las frases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NZPQ_Dv3CtGt"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xjm4QgqSCtGu"
   },
   "source": [
    "A cargar datos del archivo imdb_labelled.txt y mostramos su primer valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fnFsGosPCtGu"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('imdb_labelled.txt', names=['frases','label'], sep='\\t')\n",
    "print(df.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hXngJF1CCtGx"
   },
   "source": [
    "Una valoración bastante negativa... como podeis ver el label 0 es \"negativo\", así que 1 será \"positivo\" (analizando el sentimiento de la frase)\n",
    "\n",
    "Preparemos los datos, para tener un test y un train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PMrDzBpiCtGy"
   },
   "outputs": [],
   "source": [
    "frases = df['frases'].values\n",
    "y = df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dN4sv3XiCtGz"
   },
   "outputs": [],
   "source": [
    "frases_train, frases_test, y_train, y_test = train_test_split(frases, y, test_size=0.25, random_state=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_snzD_qUCtGz"
   },
   "source": [
    "Ahora viene el momento de crear nuestro bag of words, para eso usaremos CountVectorizer de sklearn, que lo entrenaremos con las palabras/frases del train y luego aplicaremos a cada set de frases train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pD6QqeRzCtG0"
   },
   "outputs": [],
   "source": [
    "vectorizador = CountVectorizer()\n",
    "vectorizador.fit(frases_train)\n",
    "\n",
    "x_train = vectorizador.transform(frases_train)\n",
    "x_test = vectorizador.transform(frases_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MbN2LNvLCtG1"
   },
   "outputs": [],
   "source": [
    "print(x_train[0,:])\n",
    "print(vectorizador.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xiBonFeECtG1"
   },
   "source": [
    "## 2. Primer bloque - Regresión Logistica con Bag Of Words\n",
    "\n",
    "Para empezar carguemos esas librerías que nos hacen falta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KoV2DbHSCtG2"
   },
   "source": [
    "### 2.1 Cargamos las librerias para la Regresión Logística y la entrenamos con cross validation buscando el mejor parámetro C de la regresion logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Miz00EfCtG2"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10]}\n",
    "grid = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
    "grid.fit(x_train, y_train)\n",
    "\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n",
    "print(\"Best parameters: \", grid.best_params_)\n",
    "print(\"Best estimator: \", grid.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ywrntU-DCtG2"
   },
   "outputs": [],
   "source": [
    "lr = grid.best_estimator_\n",
    "lr.fit(x_train, y_train)\n",
    "lr.predict(x_test)\n",
    "\n",
    "score_test = lr.score(x_test, y_test)\n",
    "\n",
    "print('Accuracy for IMDB data in test data: {:.4f}'.format(score_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ATOc96V7CtG3"
   },
   "source": [
    "## 3.Segundo bloque - Vayamos a por una red neuronal\n",
    "\n",
    "Una red sencilla, por ahora nada de RNN\n",
    "\n",
    "Vamos a por las librerias que necesitamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VjaohrgACtG3"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras as ks\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0uE9UTJWCtG3"
   },
   "source": [
    "Veamos cuantas dimensiones tengo para la entrada de la primera capa de la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r7I7-Ns1CtG4"
   },
   "outputs": [],
   "source": [
    "input_dim = x_train.shape[1]\n",
    "print('Numero dimensiones:', input_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SF6-UPJ6CtG4"
   },
   "source": [
    "Definimos el modelo de red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bmr_99EWCtG4"
   },
   "outputs": [],
   "source": [
    "model = ks.Sequential()\n",
    "model.add(ks.layers.Dense(512, input_dim=input_dim, activation='relu'))\n",
    "model.add(ks.layers.Dropout(0.5))\n",
    "model.add(ks.layers.Dense(256, activation='relu'))\n",
    "model.add(ks.layers.Dropout(0.5))\n",
    "model.add(ks.layers.Dense(50, activation='relu'))\n",
    "model.add(ks.layers.Dropout(0.5))\n",
    "model.add(ks.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8kQ6oqKrCtG4"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XDix1UKQCtG5"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', \\\n",
    "              optimizer='adam', \\\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4-Vpd548CtG5"
   },
   "source": [
    "Entrenemos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p3rdaXBqCtG5"
   },
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test), batch_size=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0InwhMENCtG6"
   },
   "outputs": [],
   "source": [
    "plt.title('Cross Entropy Loss')\n",
    "plt.plot(history.history['loss'], color='blue', label='train')\n",
    "plt.plot(history.history['val_loss'], color='orange', label='test')\n",
    "plt.show()\n",
    "\n",
    "plt.title('Classification Accuracy')\n",
    "plt.plot(history.history['accuracy'], color='blue', label='train')\n",
    "plt.plot(history.history['val_accuracy'], color='orange', label='test')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HTxvDi2MCtG6"
   },
   "source": [
    "Podemos ver que la red neurona facilmente entra en overfitting... asi que la regresión logística, con menos esfuerzo, funcionan parecido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ydKH9hbyCtG6"
   },
   "outputs": [],
   "source": [
    "_,score_test = model.evaluate(x_test, y_test)\n",
    "\n",
    "print('Accuracy for IMDB data in test data with NN: {:.4f}'.format(score_test))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "V-d-nn-vrs-logreg-sentimentanalysis-v2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
