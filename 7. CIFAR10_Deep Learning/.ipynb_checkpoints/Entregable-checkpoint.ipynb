{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#1.-Librerias\" data-toc-modified-id=\"1.-Librerias-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>1. Librerias</a></span></li><li><span><a href=\"#2.-Arquitectura-de-red-del-modelo\" data-toc-modified-id=\"2.-Arquitectura-de-red-del-modelo-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>2. Arquitectura de red del modelo</a></span></li><li><span><a href=\"#3.-Optimizador,-función-error\" data-toc-modified-id=\"3.-Optimizador,-función-error-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>3. Optimizador, función error</a></span></li><li><span><a href=\"#4.-Preparamos-los-datos\" data-toc-modified-id=\"4.-Preparamos-los-datos-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>4. Preparamos los datos</a></span></li><li><span><a href=\"#5.-Entrenamiento\" data-toc-modified-id=\"5.-Entrenamiento-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>5. Entrenamiento</a></span></li><li><span><a href=\"#6.-Evaluamos-los-resultados\" data-toc-modified-id=\"6.-Evaluamos-los-resultados-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>6. Evaluamos los resultados</a></span></li><li><span><a href=\"#7.-Guardamos-el-modelo-para-futuras-evaluaciones\" data-toc-modified-id=\"7.-Guardamos-el-modelo-para-futuras-evaluaciones-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>7. Guardamos el modelo para futuras evaluaciones</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dWY7kSPW9oJm"
   },
   "source": [
    "![Nuclio logo](https://nuclio.school/wp-content/uploads/2018/12/nucleoDS-newBlack.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e5awq5ZU9oJn",
    "tags": []
   },
   "source": [
    "## 1. Librerias\n",
    "\n",
    "Para empezar carguemos esas librerias que nos hacen falta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6e89W2u_9oJo"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras as ks\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6_dptlpJ9oJp"
   },
   "source": [
    "## 2. Arquitectura de red del modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JoDemzDV9oJp"
   },
   "outputs": [],
   "source": [
    "model = ks.Sequential()\n",
    "\n",
    "model.add(ks.layers.Conv2D(32, (3, 3), strides=1, activation='relu', \n",
    "                           padding='same', input_shape=(32,32,3)))\n",
    "model.add(ks.layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(ks.layers.Flatten())\n",
    "model.add(ks.layers.Dense(32, activation='relu'))\n",
    "model.add(ks.layers.Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rhpzEhLy9oJq"
   },
   "source": [
    "Para revisar un modelo, nos basta con llamar al método **.summary()** del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QPzKurY89oJq"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y6bEaf7l9oJq"
   },
   "source": [
    "## 3. Optimizador, función error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eDfwXObn9oJr"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qHBg7wfE9oJr"
   },
   "source": [
    "## 4. Preparamos los datos\n",
    "\n",
    "Cargamos los datos de CIFAR10 de los datasets directamente de las librerias de Keras. Estos ya estan dispuestos en train and test\n",
    "\n",
    "**Detalle importante:** \n",
    "> La red neuronal requiere que los inputs sean números reales, y lo haremos forzando la division de los valores de dentro de las matrices 28x28 (que tienen valoress del 0 al 255) por 255.0 (un real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9mZWEbQc9oJr"
   },
   "outputs": [],
   "source": [
    "cifar10 = ks.datasets.cifar10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j8A9za5z9oJr"
   },
   "outputs": [],
   "source": [
    "y_train_label = y_train\n",
    "\n",
    "#y_test = ks.utils.to_categorical(y_test)\n",
    "#y_train = ks.utils.to_categorical(y_train)\n",
    "\n",
    "y_test\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bQf1GueY9oJs"
   },
   "source": [
    "Obtenemos un array con todas las labels de CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EJR1ydE99oJs"
   },
   "outputs": [],
   "source": [
    "cifar10_labels = [\n",
    "'airplane', # id 0\n",
    "'automobile',\n",
    "'bird',\n",
    "'cat',\n",
    "'deer',\n",
    "'dog',\n",
    "'frog',\n",
    "'horse',\n",
    "'ship',\n",
    "'truck',\n",
    "]\n",
    "\n",
    "print('Number of labels: %s' % len(cifar10_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "61GhgQs49oJs"
   },
   "source": [
    "Pintemos una muestra de las imagenes del dataset CIFAR10, a ver si se parece en algo a lo que esperamos.\n",
    "Primero, vemos que tipos de datos tengo, después mapeamos esas matrices en una escala de grises utilizando el método **.get_cmap()** de PlotLy con los nueve primeros números del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9-Dk8dgQ9oJs"
   },
   "outputs": [],
   "source": [
    "# Pintemos una muestra de las las imagenes del dataset MNIST\n",
    "\n",
    "print('Train: X=%s, y=%s' % (x_train.shape, y_train.shape))\n",
    "print('Test: X=%s, y=%s' % (x_test.shape, y_test.shape))\n",
    "\n",
    "for i in range(9):\n",
    "\n",
    "    plt.subplot(330 + 1 + i)\n",
    "    plt.imshow(x_train[i], cmap=plt.get_cmap('gray'))\n",
    "    plt.title(cifar10_labels[y_train_label[i,0]])\n",
    "\n",
    "plt.subplots_adjust(hspace = 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WRm5syYA9oJt"
   },
   "source": [
    "Como vamos a querer ir haciendo validación a la vez que entrenamos (muy practico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ll_ESZXN9oJt"
   },
   "outputs": [],
   "source": [
    "x_val = x_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "\n",
    "x_train = x_train[:-10000]\n",
    "y_train = y_train[:-10000]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "857gyhgz9oJt"
   },
   "source": [
    "Cuando añadimos convoluciones, necesitamos \"pre-tratar los datos\", porque **la convolución espera una matriz de 4 campos** (más parecido a \"imagenes\"), en el caso de MNIST. CIFAR10 ya tiene el shape adecuado, así que no tenemos que hacer nada, pero como siempre decimos: es mejor que comprobeis su tamaño.\n",
    "\n",
    "Por eso, al salir de la Convolution, hay que hacer un Flatten, porque las capas FullDense esperan arrays, no matrices!!\n",
    "\n",
    "Luego lo imprimimos para ver que todo está correcto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GsD9N7Jf9oJt"
   },
   "outputs": [],
   "source": [
    "# Validamos el resultado\n",
    "print('Train: X=%s, y=%s' % (x_train.shape, y_train.shape))\n",
    "print('Test: X=%s, y=%s' % (x_test.shape, y_test.shape))\n",
    "print('Validation: X=%s, y=%s' % (x_val.shape, y_val.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x4CSQVcD9oJu"
   },
   "source": [
    "## 5. Entrenamiento\n",
    "\n",
    "Ya podemos ponernos a entrenar el modelo!! Ojo, que hemos de entrenar contra los datos convertidos al formato que espera la Convolution.\n",
    "\n",
    "Empezaremos con 30 epocs, es decir, 30 pasadas completas del dataset (que a su vez sera con mini-batches internamente), fijando un batch de 64\n",
    "\n",
    "El metodo .fit() nos permite, definir además si disponemos de varias CPUs, GPUs, y si queremos ir validando datos a cada fin de epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WVDxMUFK9oJu"
   },
   "outputs": [],
   "source": [
    "t = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ecp-nOVj9oJu"
   },
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, epochs=20, \n",
    "                    use_multiprocessing=False, batch_size= 512, \n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OPFPUNcJ9oJu"
   },
   "outputs": [],
   "source": [
    "elapsed_time = datetime.timedelta(seconds=(time.perf_counter() - t))\n",
    "\n",
    "print('Tiempo de entrenamiento:', elapsed_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n6Byf3JG9oJu"
   },
   "source": [
    "## 6. Evaluamos los resultados\n",
    "\n",
    "Obtengamos una grafica de como el error y la accuracy van evolucionando en cada epoch en los datos de entrenamiento y en la validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j9IaZ3-W9oJv"
   },
   "outputs": [],
   "source": [
    "_, acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('> %.3f' % (acc * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GrH8OFmF9oJv"
   },
   "outputs": [],
   "source": [
    "plt.title('Cross Entropy Loss')\n",
    "plt.plot(history.history['loss'], color='blue', label='train')\n",
    "plt.plot(history.history['val_loss'], color='orange', label='val')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.title('Classification Accuracy')\n",
    "plt.plot(history.history['accuracy'], color='blue', label='train')\n",
    "plt.plot(history.history['val_accuracy'], color='orange', label='val')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BT7Xpz409oJv"
   },
   "source": [
    "El coste podemos ver que es estable y es en el epoch 15 que se fija en un valor. Además la accuracy baila alrededor de 0.10. No se puede decir que sea un modelo muy bueno.\n",
    "\n",
    "Veamos que tipo de predicciones estoy obteniendo sobre el conjunto de test (vamos a pintar las imagenes y sus clasificaciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G4gqi32X9oJw"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3blmpM1k9oJw"
   },
   "source": [
    "Una de las ventajas de Python es que hay montones de funciones y código realizado por terceras personas. Aquí me he fusilado unas bonitas funciones (que he adaptado un poco a mis necesidades) para poder pintar las imagenes, su label (ground truth) y las clasificaciones que hemos realizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P02wctIA9oJw"
   },
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, true_label, img):\n",
    "  predictions_array, true_label, img = predictions_array, true_label[i], img[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "\n",
    "  plt.imshow(img, cmap=plt.cm.binary)\n",
    "\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "  if predicted_label == true_label:\n",
    "    color = 'blue'\n",
    "  else:\n",
    "    color = 'red'\n",
    "\n",
    "  plt.xlabel(\"{} {:2.0f}% ({})\".format(predicted_label,\n",
    "                                100*np.max(predictions_array),\n",
    "                                true_label[0]),\n",
    "                                color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "  predictions_array, true_label = predictions_array, true_label[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks(range(10))\n",
    "  plt.yticks([])\n",
    "  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
    "  plt.ylim([0, 1])\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "  thisplot[predicted_label].set_color('red')\n",
    "  thisplot[true_label[0]].set_color('blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kCoAXQ6e9oJw"
   },
   "source": [
    "Dibujamos las primeras imagenes, con las predicciones y sus valores reales (un total de 20 imagenes, para no abusar de vuestros laptops)\n",
    "\n",
    "Coloreamos las prediciones correctas en azul y los fallos en rojo. Aunque primero he impreso las etiquetas para que tengamos una referencia al grafico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4jcGyOkV9oJx"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for l in cifar10_labels:\n",
    "    print(i, l)\n",
    "    i += 1\n",
    "\n",
    "num_rows = 5\n",
    "num_cols = 4\n",
    "start = 650\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(num_images):\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "  plot_image(i+start, predictions[i+start], y_test, x_test)\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "  plot_value_array(i+start, predictions[i+start], y_test)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Guardamos el modelo para futuras evaluaciones\n",
    "\n",
    "Id cambiando los nombres del archivo para ir guardando los diversos proyectos.\n",
    "Aquí lo guardamos en \"local\", pero recordad que lo ideal es que lo guardeis en Google Drive (teneis que montar la unidad, fijar la ruta y allí guardar el modelo .h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wEaRpWif9oJx"
   },
   "outputs": [],
   "source": [
    "model.save('cifar10_base_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RUeYZHYd9oJx"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "cnn-cifar10-tf2-v0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
